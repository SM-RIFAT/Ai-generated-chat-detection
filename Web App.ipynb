{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6253c8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\golam\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "C:\\Users\\golam\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "C:\\Users\\golam\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.0.106:5000\n",
      "Press CTRL+C to quit\n",
      "192.168.0.106 - - [04/Jun/2025 05:20:29] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.0.106 - - [04/Jun/2025 05:20:29] \"GET /static/res/linkedin.png HTTP/1.1\" 200 -\n",
      "192.168.0.106 - - [04/Jun/2025 05:20:29] \"GET /static/res/github.png HTTP/1.1\" 200 -\n",
      "192.168.0.106 - - [04/Jun/2025 05:20:29] \"GET /static/res/web.png HTTP/1.1\" 200 -\n",
      "192.168.0.106 - - [04/Jun/2025 05:20:29] \"GET /static/res/medium.png HTTP/1.1\" 200 -\n",
      "192.168.0.106 - - [04/Jun/2025 05:20:30] \"GET /static/res/favicon.png HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, render_template\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "import tokenizers\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "from transformers import AutoTokenizer, DebertaForSequenceClassification\n",
    "\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import TrainingArguments\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import Trainer\n",
    "\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.config['TEMPLATES_AUTO_RELOAD'] = True\n",
    "\n",
    "try:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"results/sent_model/\")\n",
    "except OSError:\n",
    "    print(f\"Model not found locally. Downloading {model_name}...\")\n",
    "    model = BertModel.from_pretrained('bert-base-cased')\n",
    "\n",
    "# Step 4: Define a tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"results/sent_model/\")\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Removes special characters from the given text\n",
    "    \"\"\"\n",
    "    cleaned_text = \"\"\n",
    "    for char in text:\n",
    "        if char.isalnum() or char.isspace():\n",
    "            cleaned_text += char\n",
    "    return cleaned_text\n",
    "\n",
    "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
    "def index():\n",
    "    if request.method == \"POST\":\n",
    "        file = request.files[\"file\"]\n",
    "        text = file.read().decode(\"utf-8\")\n",
    "        cleaned_text = clean_text(text)\n",
    "        question = request.form[\"question\"]\n",
    "\n",
    "        inputs = tokenizer(question, return_tensors = \"pt\", truncation=True, padding=True, max_length=512)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(**inputs)\n",
    "            logits = pred.logits\n",
    "            predicted_class = torch.argmax(logits, dim=1).item()\n",
    "            print(predicted_class)\n",
    "\n",
    "        if(int(predicted_class) == 1):\n",
    "            answer = \"AI Generated Text\"\n",
    "        else:\n",
    "            answer = \"Human Generated Text\"\n",
    "\n",
    "        return render_template(\"result.html\", question=question, answer=answer)\n",
    "    else:\n",
    "        return render_template(\"question.html\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079c6e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
